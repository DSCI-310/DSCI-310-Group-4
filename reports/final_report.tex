% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={DSCI 310 Group 4: Default payments in Taiwan and comparison of the predictive accuracy of probability of default},
  pdfauthor={Shravan Chaniara, Jordan Yu, Diana Liang, Hannah Martin},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{DSCI 310 Group 4: Default payments in Taiwan and comparison of
the predictive accuracy of probability of default}
\author{Shravan Chaniara, Jordan Yu, Diana Liang, Hannah Martin}
\date{}

\begin{document}
\maketitle

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

Amidst growing financial insecurity during the pandemic, unsecured debt
has continued to rise (Frech (2021)). Consequently, the consumer credit
market and risk prediction has been a matter of great speculation and
fear, lest there be a repeat of the financial crises that rocked the
economic world in the late 2000s: In 2006, Taiwan was rocked by a credit
card debt crisis with debt from credit cards and cash cards reaching
\$268 billion USD and over half a million people unable to repay their
loans (Yeh (2009)). As many could barely afford to pay the minimum
credit card debt balance every month or continued to default on their
payments, significant societal problems consequently plagued the
country, many banks incurred heavy losses and the government eventually
needed to step in to stabilize the financial system (Yeh (2009)). This
situation arose because many banks in Taiwan had lowered the
requirements for credit card approval in order to gain more customers
within the increasingly competitive industry (Tsai (2010)). Such
examples indicate that a strict assessment of an applicant's capability
to make their card payment is critical to a well-developed financial
system and a business's survivability in the banking industry.

This project focuses on the case of customers default payments in Taiwan
and finds the predictive accuracy of the probability of the customers to
default. The purpose of this study is to assess the true probability of
default because the real probability of default is unknown.

\hypertarget{dataset-information}{%
\subsection{Dataset Information}\label{dataset-information}}

This project used the data Dua (2016) from UCI Machine learning
repository. As the response variable, this project used data from a
binary variable, \texttt{default\ payment} (Yes = 1, No = 0). The
following 23 factors were considered as explanatory variables in this
study, which was based on a review of the literature:

\begin{itemize}
\tightlist
\item
  Amount of the given credit (NT dollar): it includes both the
  individual consumer credit and his/her family (supplementary) credit.
\item
  Gender (1 = male; 2 = female).
\item
  Education (1 = graduate school; 2 = university; 3 = high school; 4 =
  others).
\item
  Marital status (1 = married; 2 = single; 3 = others).
\item
  Age (year).
\item
  History of past payment. The measurement scale for the repayment
  status is: -1 = pay duly; 1 = payment delay for one month; 2 = payment
  delay for two months . . . 8 = payment delay for eight months; 9 =
  payment delay for nine months and above.
\item
  Amount of bill statement (NT dollar).
\item
  Amount of previous payment (NT dollar).
\end{itemize}

The objective of this project is to maintain ease of interpretation for
the average reader. In line with this goal, we will simplify the models
and methods of analysis we choose to use as well as exclude some
features in the data set in favor of greater readability.

\hypertarget{methods-and-results}{%
\section{Methods and Results}\label{methods-and-results}}

\hypertarget{exploratory-data-analysis}{%
\subsubsection{Exploratory Data
Analysis}\label{exploratory-data-analysis}}

First, we load and tidy the data. The dataset was split into a 80\%
training and 20\% testing set. The model will be built using only the
training data. This gives the abilithy to compute a final performance
metric for our model by evaluating it on the testing data.
train\_test\_split() function shuffles the data to ensure the data
ending up in the training and test sets is randomized.

Before any data analysis can be done let's check if the dataset has
null/missing values that may affect further analysis: The dataset is
super clean, and no missing value is found.

\hypertarget{statistics-information}{%
\subsubsection{Statistics information}\label{statistics-information}}

This part we have a look at some basic statistics of the training set:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0182}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0328}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0438}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0365}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0401}}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 50\tabcolsep) * \real{0.0584}}@{}}
\caption{Summary Stats}\tabularnewline
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\ldots1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
ID
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
LIMIT\_BAL
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
SEX
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
EDUCATION
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
MARRIAGE
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
AGE
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_0
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_6
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT6
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT6
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
default\_payment
\end{minipage} \\
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{\linewidth}\raggedright
\ldots1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
ID
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
LIMIT\_BAL
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
SEX
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
EDUCATION
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
MARRIAGE
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
AGE
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_0
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_6
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
BILL\_AMT6
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
PAY\_AMT6
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
default\_payment
\end{minipage} \\
\midrule
\endhead
mean & 14976.622 & 166849.3 & 1.6046667 & 1.8533750 & 1.5550417 &
35.41963 & -0.0139167 & -0.1339167 & -0.1648333 & -0.216500 & -0.262750
& -0.2915833 & 51069.80 & 49050.72 & 46870.75 & 43104.47 & 40229.08 &
38779.37 & 5616.939 & 5887.682 & 5167.88 & 4829.719 & 4737.681 &
5215.203 & 0.2236250 \\
std & 8653.231 & 129755.4 & 0.4889324 & 0.7868091 & 0.5224766 & 9.18461
& 1.1263995 & 1.2045235 & 1.2035255 & 1.173677 & 1.139342 & 1.1523676 &
73745.22 & 71162.25 & 69436.39 & 63907.82 & 60576.64 & 59440.28 &
16379.133 & 23028.080 & 17554.29 & 16048.881 & 15344.499 & 18288.995 &
0.4166822 \\
min & 1.000 & 10000.0 & 1.0000000 & 0.0000000 & 0.0000000 & 21.00000 &
-2.0000000 & -2.0000000 & -2.0000000 & -2.000000 & -2.000000 &
-2.0000000 & -154973.00 & -69777.00 & -157264.00 & -170000.00 &
-81334.00 & -339603.00 & 0.000 & 0.000 & 0.00 & 0.000 & 0.000 & 0.000 &
0.0000000 \\
max & 30000.000 & 1000000.0 & 2.0000000 & 6.0000000 & 3.0000000 &
75.00000 & 8.0000000 & 8.0000000 & 8.0000000 & 8.000000 & 8.000000 &
8.0000000 & 964511.00 & 983931.00 & 1664089.00 & 891586.00 & 927171.00 &
961664.00 & 873552.000 & 1684259.000 & 896040.00 & 621000.000 &
426529.000 & 528666.000 & 1.0000000 \\
\bottomrule
\end{longtable}

We can see the following information:

\begin{itemize}
\tightlist
\item
  The average amount of given credit in NT dollars is 166849.320000;
\item
  The average age of all clients is 35.419625, etc.
\end{itemize}

To better understand the correlation between variables, we would like to
compute and visualize the correlations:

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/heatmap} 

}

\caption{Heat Map}\label{fig:heat-map}
\end{figure}

The heatmap shows some positive/negative correlations:

Positive correlations:

\begin{itemize}
\tightlist
\item
  \texttt{Default\ payment} - \texttt{PAY\_0} to \texttt{PAY\_6}
  (Repayment status from April to September, 2005);
\item
  \texttt{Limit\ balance} - \texttt{BILL\_AMT1} to \texttt{BILL\_AMT6}
  (Amount of bill statement from April to September, 2005), etc.
\end{itemize}

Negative correlations:

\begin{itemize}
\tightlist
\item
  \texttt{Limit\ balance} - \texttt{PAY\_0} to \texttt{PAY\_6}
  (Repayment status from April to September, 2005), etc.
\end{itemize}

Specifically, \texttt{PAY\_0} has the highest correlation with
\texttt{default\_payment}. This will give us a signal that
\texttt{PAY\_0} plays an important role for predicting
\texttt{default\_payment}.

\hypertarget{exploring-variables}{%
\subsection{Exploring variables}\label{exploring-variables}}

\hypertarget{limit_bal}{%
\subsubsection{LIMIT\_BAL}\label{limit_bal}}

First, we look at the amount of given credit (in NT dollars). Credit
card limits are likely an indictor of how wealthy someone is since banks
tend to give higher limits to clients that have more money with them.
Thus, this may be an important feature when predicting if someone is
able to pay the bill on time.

\begin{figure}
\includegraphics[width=0.8\linewidth]{../results/limit_bal_dist} \caption{Limit Balance Distribution}\label{fig:limit-dist}
\end{figure}

\hypertarget{repayment-status}{%
\subsubsection{Repayment Status}\label{repayment-status}}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/repayment_status_PAY_0} 

}

\caption{Repayment Status PAY_0}\label{fig:repayment-status-PAY-0}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/repayment_status_PAY_2} 

}

\caption{Repayment Status PAY_2}\label{fig:repayment-status-PAY-2}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/repayment_status_PAY_3} 

}

\caption{Repayment Status PAY_3}\label{fig:repayment-status-PAY-3}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/repayment_status_PAY_4} 

}

\caption{Repayment Status PAY_4}\label{fig:repayment-status-PAY-4}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/repayment_status_PAY_5} 

}

\caption{Repayment Status PAY_5}\label{fig:repayment-status-PAY-5}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/repayment_status_PAY_6} 

}

\caption{Repayment Status PAY_6}\label{fig:repayment-status-PAY-6}
\end{figure}

Looking at the above plots on repayment status shows that if a client
defaults on their payment for 2 months (e.g PAY\_X = 2), it is a
indicator to predict that default\_payment = 1. It looks like repayment
status will be an important feature in the model.

\hypertarget{analysis}{%
\subsection{Analysis}\label{analysis}}

\hypertarget{class-imbalance}{%
\subsubsection{Class Imbalance}\label{class-imbalance}}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/class_imbalance} 

}

\caption{Count Plot}\label{fig:class-imbalance}
\end{figure}

The above plot shows the percentage of rows with default payment = 0
versus default payment = 1. Cleary there is class imbalance in this
dataset. Because of this, we will use the area under the Receiver
Operating Characterisitc curve (ROC AUC) as our primary metric to
evaluate our model instead of accuracy, which tends to be missleading in
cases of class imbalance. ROC AUC evalauates how good the model is as
distinguishing between classes, and gives a more accurate sense of how
well our model generalizes when dealing with class imbalance.

\hypertarget{preprossesing}{%
\subsubsection{Preprossesing}\label{preprossesing}}

We apply scaling to numeric features to ensure the model built will be
robust and not sensitive to the scale of each individual feature. To do
this, we use the StandardScaler() function to set the sample mean to 0
and standard deviation to 1.

To handle categorical values, we will apply one-hot-encoding. This
creates binary dummy variables for each category. Next, we apply scaling
and one-hot-encoding through using a column transformer, which applies
the transformations to each column specified.

\hypertarget{model-0-dummy-classifier}{%
\subsubsection{Model 0: Dummy
Classifier}\label{model-0-dummy-classifier}}

Firstly, we will try a baseline model to act as a comparison measure for
the final model built. Using a pipeline to do this ensures that the
model is built using just the training data, and that the testing data
has no influence on the model. 5-fold Cross validation is used to give a
more robust measure of performance error. K-fold Cross-validation spilts
the training data into k folds, and each time one fold is the validation
set. Each fold fits the model on the training portion and uses one fold
as a validation set to calculate a performance metric, which can be
averaged to get a overall score of how well the model does. This ensures
that outliers don't negatively influence the performance metric.

\begin{longtable}[]{@{}rrrr@{}}
\toprule
fit\_time & score\_time & test\_score & train\_score \\
\midrule
\endhead
0.0495319 & 0.0170791 & 0.5 & 0.5 \\
0.0465059 & 0.0162730 & 0.5 & 0.5 \\
0.0472391 & 0.0171912 & 0.5 & 0.5 \\
0.0462983 & 0.0167217 & 0.5 & 0.5 \\
0.0470541 & 0.0182700 & 0.5 & 0.5 \\
\bottomrule
\end{longtable}

\hypertarget{model-1-logistic-regression}{%
\subsubsection{Model 1: Logistic
Regression}\label{model-1-logistic-regression}}

Next, a logistic regression model is fitted to the training data.
Logistic regression uses the training data to learn coefficients, which
then can be used to calculate prediction probabilities of the each class
using the sigmoid function. This allows us to calculate the probability
of a client defaulting on their credit card based on their data. The
hyperparameter C is used to control the fundatamental tradeoff of bias
and variance, to reduce the likeliness of the model overfitting or
underfitting. We chose logistic regression over more complex classifiers
such as ensemble trees because it is easier to interpret and efficient
to train. The predicted coeficients give information about feature
importance and direction of association, making the model easily
interpreted. Moreover, since the dataset is significantly larger than
the number of features, logistic regression is less likely to overfit
because it is a low variance model.

Hyperparameter optimization is carried out to find the best value of C
for the data in hopes to reduce bias and variance. Cross-validation is
used to test how well the model performs on unseen data during
hyperparemter opimization, enabling performance metrics to be calculated
to compare different values of C.

\begin{longtable}[]{@{}rrr@{}}
\toprule
C & Train Scores & CV Scores \\
\midrule
\endhead
0.0316228 & 0.7724754 & 0.7689002 \\
0.1000000 & 0.7727518 & 0.7686736 \\
0.3162278 & 0.7728306 & 0.7684365 \\
1.0000000 & 0.7729194 & 0.7682234 \\
3.1622777 & 0.7729977 & 0.7678970 \\
10.0000000 & 0.7730728 & 0.7674601 \\
31.6227766 & 0.7731342 & 0.7671300 \\
\bottomrule
\end{longtable}

Next, the logistic regression model with the optimized C value is fitted
to the training data. The model is built using pipelines to ensure all
data preprocessing is constant and that no information from the testing
set leaks into the training of the model.

\hypertarget{feature-importance}{%
\subsubsection{Feature Importance}\label{feature-importance}}

Next, we will look at feature importance. In logistic regression, the
magnitude and direction of the learned coefficients explain the
relationship between a explanatory feature and the response variable.

\begin{longtable}[]{@{}rr@{}}
\toprule
coefficient & absolute\_value \\
\midrule
\endhead
1.0613115 & 1.0613115 \\
-1.0045704 & 1.0045704 \\
0.7219127 & 0.7219127 \\
-0.6688425 & 0.6688425 \\
-0.3219945 & 0.3219945 \\
-0.3176690 & 0.3176690 \\
-0.3148366 & 0.3148366 \\
-0.2489065 & 0.2489065 \\
0.2488997 & 0.2488997 \\
0.2450337 & 0.2450337 \\
-0.2250865 & 0.2250865 \\
0.2146013 & 0.2146013 \\
-0.1767683 & 0.1767683 \\
-0.1764516 & 0.1764516 \\
-0.1757003 & 0.1757003 \\
-0.1721139 & 0.1721139 \\
0.1665569 & 0.1665569 \\
-0.1638805 & 0.1638805 \\
-0.1632858 & 0.1632858 \\
0.1605075 & 0.1605075 \\
-0.1488593 & 0.1488593 \\
-0.1480731 & 0.1480731 \\
0.1464547 & 0.1464547 \\
-0.1462427 & 0.1462427 \\
0.1458649 & 0.1458649 \\
0.1420812 & 0.1420812 \\
0.1373272 & 0.1373272 \\
0.1355065 & 0.1355065 \\
0.1346587 & 0.1346587 \\
0.1325932 & 0.1325932 \\
0.1277497 & 0.1277497 \\
0.1256826 & 0.1256826 \\
-0.1227187 & 0.1227187 \\
0.1209245 & 0.1209245 \\
0.1199460 & 0.1199460 \\
0.1010633 & 0.1010633 \\
-0.0964676 & 0.0964676 \\
-0.0955501 & 0.0955501 \\
-0.0954486 & 0.0954486 \\
0.0942384 & 0.0942384 \\
0.0928493 & 0.0928493 \\
0.0898831 & 0.0898831 \\
-0.0848013 & 0.0848013 \\
-0.0839578 & 0.0839578 \\
0.0808301 & 0.0808301 \\
-0.0800034 & 0.0800034 \\
-0.0766308 & 0.0766308 \\
-0.0752523 & 0.0752523 \\
0.0677422 & 0.0677422 \\
-0.0666298 & 0.0666298 \\
0.0648119 & 0.0648119 \\
-0.0618421 & 0.0618421 \\
-0.0585649 & 0.0585649 \\
-0.0558367 & 0.0558367 \\
0.0548550 & 0.0548550 \\
-0.0491085 & 0.0491085 \\
-0.0457311 & 0.0457311 \\
-0.0457029 & 0.0457029 \\
0.0456451 & 0.0456451 \\
-0.0449203 & 0.0449203 \\
-0.0445626 & 0.0445626 \\
0.0434407 & 0.0434407 \\
0.0422952 & 0.0422952 \\
0.0398872 & 0.0398872 \\
-0.0398413 & 0.0398413 \\
0.0373981 & 0.0373981 \\
-0.0327837 & 0.0327837 \\
-0.0316877 & 0.0316877 \\
0.0315146 & 0.0315146 \\
0.0310946 & 0.0310946 \\
0.0310455 & 0.0310455 \\
0.0240199 & 0.0240199 \\
0.0238222 & 0.0238222 \\
0.0231004 & 0.0231004 \\
0.0230929 & 0.0230929 \\
0.0228617 & 0.0228617 \\
0.0213132 & 0.0213132 \\
0.0197398 & 0.0197398 \\
0.0148494 & 0.0148494 \\
-0.0140716 & 0.0140716 \\
0.0129652 & 0.0129652 \\
-0.0119431 & 0.0119431 \\
-0.0100939 & 0.0100939 \\
-0.0091463 & 0.0091463 \\
-0.0090065 & 0.0090065 \\
0.0073979 & 0.0073979 \\
0.0073550 & 0.0073550 \\
0.0032263 & 0.0032263 \\
-0.0026832 & 0.0026832 \\
-0.0022118 & 0.0022118 \\
-0.0007705 & 0.0007705 \\
\bottomrule
\end{longtable}

The table above shows the most important features according to the
model. Positive coefficients indicate that an increase in the feature
increases the probability that the response variable is class 1, and
negative coefficients indicate that a increases in the feature decreases
the probability that the response variable is class 1.

The most important feature is repayment status in April with a 2 month
delay.

To further interpret this, the odds ratio can be calculated.
\(OR = e^{\beta}\), where \(\beta\) is a model coefficient.

The odds ratio for x0\_2 is 2.8901590141210964 can be interpreted as
clients who delayed payment for 2 months in April have about 2.9 times
the odds of defaulting their credit card payment next month than those
who did not delay for 2 months of, controlling for the other features
since there is some correlation.

It makes logical sense that this feature is important since it was
highly correlated with the response variable during the exploratory data
analysis, and because it makes sense that if someone has delayed payment
in the past they may not be able to pay in the future as well.

Another important feature is x0\_0, corresponding to repayment status in
April with a revolving credit. The magnitude is negative here meaning
that a value of 1 for this binary variable is negatively associated with
defaulting next month. This makes sense because revolving credit lets
clients pay a minimum balance instead of the full bill, making them less
likely to default. The odds ratio is calculated below.

The odds ratio is 0.3662019170982376 shows that clients who had a
repayment status of using a revolving credit in April decreases the odds
of class 1 versus class 0 by about 63\%, controlling for the other
features.

Due to the large number of features, we only looked at the first 2 most
important features, however this method can be done for the remaining
features as well.

\hypertarget{testing-the-model}{%
\subsubsection{Testing the Model}\label{testing-the-model}}

Finally, the model will be evaluated by predicting on the test dataset.
Performance metrics including area under the ROC curve, f1-score,
precision and recall will be calculated. Precision is the ratio of true
postive and total positives. Recall is the measure of the model
correctly identifying true positives. F1-score is the harmonic mean of
precision and recall.

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/roc} 

}

\caption{ROC}\label{fig:roc}
\end{figure}

The test ROC AUC is almost the same as the cross-validation ROC AUC so
we can conclude that there is little optimization bias and we are not
overfitting. Area under the ROC curve is the classifier's ability to
distinguish between classes. So 78\% of the time, the model is able to
correctly distinguish between class 0 and class 1.

\begin{longtable}[]{@{}rrrr@{}}
\toprule
\ldots1 & recall & precision & f1 score \\
\midrule
\endhead
0 & 0.359 & 0.669 & 0.467 \\
\bottomrule
\end{longtable}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{../results/confusion_matrix} 

}

\caption{Confusion matrix}\label{fig:confusion_matrix}
\end{figure}

It appears that the model does significantly better for the non-default
class, since precision, recall, and f1-score are very high. Recall is
partically low for the default class, and very high for the non-default
class. Thus this model is very good at indentifying clients who will pay
their bill on time. Precision can be intrepreted as when the model
predicts class 0 (non-default) it is correct 84\% of the time, and when
it predicts class 1 it is correct 64\% of the time, which is not as
good.

\hypertarget{discussion}{%
\section{Discussion}\label{discussion}}

Looking at the results above, the analysis has a few limitations. One of
the main limitations is the extrapolation of data. The dataset used was
from Taiwan so the model may not apply properly for financial
institutions and people outside of Taiwan. The other limitation is that
logistic regression favors interpretability over prediction accuracy.
The coefficients are easy to understand while the logistic regression is
not as accurate as other algorithms.

Another limitation of the analysis is that logistic regression is a
higher bias model than other classifiers such as ensemble trees. This
means that the model pays less attention to the training data and may
oversimplify it, resulting in less accuracy. However, the results show
that the model did very well when predicting clients who did not default
next month (class 0). The high recall and precision score for class 0
suggest this model can be very useful when trying to distinguish if a
client will pay the bill on time. Thus, this model can be used to help
financial institutions make various risk decisions about a client
including whether to offer someone a loan or whether to raise the credit
card monthly limit. A prediction probability can be calculated based on
the input features of each individual client. A prediction probability
close to 0 indicates that the client is likely to pay the credit card
bill.

According to the model, the most important feature was repayment status.
Specifically, whether or not someone delayed payment for 2 months, and
whether or not someone used a revolving credit card. This provides
insight into what features financial institutions should look for when
assessing risk for individual clients. Also, the model suggests that
giving someone a revolving credit card where they only have to pay a
minimum balance instead of the whole bill each month reduces the
probability of the client defaulting. This information could be used to
prevent the institute from losing money due to people defaulting.

Overall, the model provides insight into important features that may
benefit financial institutions when managing risk, and allows an
institute to calculate the probability that an individual client will
default.

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-default_credit_card}{}}%
Dua, \& Graff, D. 2016. \emph{UCI Machine Learning Repository: Default
of Credit Card Clients Data Set {[}Data Set{]}}. University of
California, Irvine, School of Information; Computer Science.
\url{https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients}.

\leavevmode\vadjust pre{\hypertarget{ref-Frech2021}{}}%
Frech, Houle, A. 2021. \emph{Trajectories of Unsecured Debt and Health
at Midlife}. \emph{SSM - Population Health}. Vol. 15.
\url{https://doi.org/10.1016/j.ssmph.2021.100846}.

\leavevmode\vadjust pre{\hypertarget{ref-Tsai2010}{}}%
Tsai, B.-H. 2010. \emph{Gauging Bank Efficiency During Card Insolvency
Crisis: The Case of the Taiwanese Banks}. \emph{The Journal of
Developing Areas}. Vol. 44. \url{https://doi.org/10.1353/jda.0.0087}.

\leavevmode\vadjust pre{\hypertarget{ref-Yeh2009}{}}%
Yeh, \& Lien, I-Cheng. 2009. \emph{The Comparisons of Data Mining
Techniques for the Predictive Accuracy of Probability of Default of
Credit Card Clients.} \emph{Expert Systems with Applications}. Vol.
36(2). \url{https://doi.org/10.1016/j.eswa.2007.12.020}.

\end{CSLReferences}

\end{document}
